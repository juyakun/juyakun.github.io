<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yakun Ju</title>
<style>
    .container {
        display: flex;
        justify-content: space-between;
    }

    .imgtable img {
        align-self: center;
    }
</style>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Yakun Ju",
  "alternateName": "Ju Yakun",
  "image": "https://juyakun.github.io/picture/jykh.png",
  "jobTitle": "Lecturer (Assistant Professor)",
  "worksFor": {
    "@type": "Organization",
    "name": "University of Leicester",
    "url": "https://le.ac.uk"
  },
  "email": [
    "mailto:yj174@leicester.ac.uk",
    "mailto:kelvin.yakun.ju@gmail.com"
  ],
  "sameAs": [
    "https://github.com/juyakun",
    "https://le.ac.uk/people/yakun-ju"
  ],
  "url": "https://juyakun.github.io/",
  "description": "Dr. Yakun Ju is a Lecturer at the University of Leicester. His research interests include 3D reconstruction, underwater vision, photometric stereo, and medical image processing."
}
</script>

</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Yakun Ju (举雅琨)</h1>
</div>
<table class="imgtable">
  <tr><td><a href="https://juyakun.github.io/"><img src="picture/jykh.png" alt="alt text" width="160px" /></a>&nbsp;	</td>
  <td align="left">  <p>Lecturer (Assistant Professor)<br /> 
  	 School of Computing and Mathematical Sciences, University of Leicester, Leicester LE1 7RH, UK <br /> 
	  </p>
  	Email: kelvin.yakun.ju@gmail.com  /  yj174@leicester.ac.uk <br /> 
	</p>
<br /> 
<a href="https://github.com/juyakun/juyakun.github.io/raw/main/cv2602.pdf" target="_blank">[Full CV – Feb 26]</a>	
<a href="https://le.ac.uk/people/yakun-ju">[Official Website]</a> 
<a href="https://scholar.google.co.uk/citations?user=hE10pMYAAAAJ&hl=en&oi=aoJ">[Google Scholar]</a> 
<a href="https://orcid.org/my-orcid?orcid=0000-0003-4065-4108">[ORCID]</a>
<a href=" https://www.researchgate.net/profile/Yakun-Ju">[ResearchGate]</a> 
</td>
	  
</tr></table>

<h2>Short Biography</h2>
<p>Yakun Ju has been an Assistant Professor (UK Lecturer) in the School of Computing and Mathematical Sciences at the University of Leicester (莱斯特大学), United Kingdom, since 2024. Before joining Leicester, he worked as a Research Fellow in the  <a href="https://www.ntu.edu.sg/rose/about-us/our-people">ROSE Lab (博云搜索实验室) </a> at Nanyang Technological University (南洋理工大学), Singapore (2023–2024), collaborating with Prof.  <a href="https://dr.ntu.edu.sg/cris/rp/rp00653">[Alex Chichung Kot]</a> (SAEng, IEEE Life Fellow). Prior to that, he was a Postdoctoral Fellow at The Hong Kong Polytechnic University (香港理工大学), Hong Kong SAR (2022–2023), working with Prof.  <a href="https://research.polyu.edu.hk/en/persons/kin-man-lam/">[Kin-Man Lam (林健文)]</a> (Vice President, IEEE Signal Processing Society). He received his Ph.D. in Computer Science from Ocean University of China (中国海洋大学) in 2022, supervised by  Prof. <a href="https://it.ouc.edu.cn/djy_en/list.htm">[Junyu Dong (董军宇)]</a> (National High-Level Talent Programs - Leading Talents). He received the B.Eng. degree from Sichuan University (四川大学) in 2016.</p> 

<p>Dr. Ju’s research interests include 3D reconstruction, photometric stereo, computational imaging, and underwater visual perception. His work emphasizes physically grounded and learning-based methods for dense geometry recovery and reflectance analysis in challenging environments, including underwater and medical scenes. He has authored over 70 peer-reviewed publications in leading journals and conferences such as TPAMI, TVCG, TIP, IJCV, NeurIPS, and CVPR, and holds multiple China national patents related to deep learning-based 3D surface reconstruction, which have supported technology transfer applications exceeding 400,000 CNY (approximately 55,000 USD). 
</p>
  
<h2>Academic Service</h2>
<ul>
<li><p><b>Youth Editorial Board</b>: <a href="https://link.springer.com/journal/11633">Machine Intelligence Research (MIR)</a> <br>
<li><p><b>Youth Editorial Board</b>: <a href="https://digital-library.theiet.org/journal/trit">CAAI Transactions on Intelligence Technology (CAAI TRIT)</a> <br>
<li><p><b>Associate Editor/Editorial Board</b>: <a href="https://www.sciencedirect.com/journal/applied-soft-computing/about/editorial-board">Applied Soft Computing (ASOC)</a> <br>
<li><p><b>Associate Editor/Editorial Board</b>: <a href="https://www.sciencedirect.com/journal/neurocomputing/about/editorial-board">Neurocomputing</a> <br>
<li><p><b>Associate Editor/Editorial Board</b>:  <a href="https://link.springer.com/journal/44295/editors">Intelligent Marine Technology and Systems (IMTS)</a> <br>
</p>
</p>
<li><p><b>Guest Editor</b>: <a href="https://opg.optica.org/content/feature/announcement/item/josaa-ocmaa">Journal of the Optical Society of America A (JOSA A)-SI:"Optics-Driven Computation Models"</a> <br>
<li><p><b>Guest Editor</b>: <a href="https://www.sciencedirect.com/special-issue/325118/multimodal-3d-perception-for-underwater-engineering-acoustics-optics-and-integrated-solutions">Ocean Engineering (OE)-SI:"Multimodal 3D Perception for Underwater Engineering"</a> <br>
<li><p><b>Guest Editor</b>: <a href="https://www.sciencedirect.com/journal/pattern-recognition/about/call-for-papers">Pattern Recognition (PR)-SI:"“Advances in Multimodal-Driven Video Understanding & Assessment"</a> <br>
<li><p><b>Guest Editor</b>: <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding/about/call-for-papers#advanced-computational-imaging-and-photography-measurement">Computer Vision and Image understanding (CVIU)-SI: "Computational & Photography Imaging"</a> <br>
</p>
</p>
<li><p><b>Proceedings Chair</b>: <a href="https://bmvc2026.bmva.org/">British Machine Vision Conference 2026 (BMVC 2026) </a> <br>
</p>
</p>
<li><p><b>Conference Workshop Chair</b>: <a href="https://p3dmm2026.github.io/">IEEE ICME 2026W: Physical Principles for Reliable 3D Modelling in Multimedia </a> <br>
<li><p><b>Conference Workshop Chair</b>: <a href="https://2025.ieeeicme.org/workshops/#1736680093350-f12533ce-6079">IEEE ICME 2025W: Multimedia in Underwater Information Processing and Exploration </a> <br>

</ul>
	
<h2>Selected Publications</h2> 
<ul> <li><p>Revisiting One-stage Deep Uncalibrated Photometric Stereo via Fourier Embedding <br />
  <b>Yakun Ju</b>, Boxin Shi, Bihan Wen, Kin-Man Lam, Xudong Jiang, Alex C. Kot <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025
  <a href="https://ieeexplore.ieee.org/document/10947620">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>Deep Learning Methods for Calibrated Photometric Stereo and Beyond <br />
  <b>Yakun Ju</b>, Kin-Man Lam, Wuyuan Xie, Huiyu Zhou, Junyu Dong, Boxin Shi <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024
  <a href="https://ieeexplore.ieee.org/abstract/document/10497891">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>Photometric regularization for 3D gaussian splatting in multi-view surface projection <br />
  <b>Yakun Ju</b>,Yuying Zhao, Jun Xiao, Cong Zhang, Zheheng Jiang, Huiyu Zhou, Wei Zhou, Hui Yu, Junyu Dong <br />
<i>IEEE Journal of Selected Topics in Signal Processing (JSTSP), 2025
  <a href="https://ieeexplore.ieee.org/abstract/document/11192617">[Paper]</a>
</i></p>
</li>
</ul>	
  
<ul> <li><p>Normattention-PSN: A High-Frequency Region Enhanced Photometric Stereo Network with Normalized Attention<br />
  <b>Yakun Ju</b>, Boxin Shi, Muwei Jian, Lin Qi, Junyu Dong, Kin-Man Lam <br />
<i>International Journal of Computer Vision (IJCV), 2022
  <a href="https://link.springer.com/article/10.1007/s11263-022-01684-8">[Paper]</a>
</i></p>
</li>
</ul>	  

<ul> <li><p>Recovering Surface Normal and Arbitrary Images: A Dual Regression Network for Photometric Stereo <br />
  <b>Yakun Ju</b>, Junyu Dong, Sheng Chen <br />
<i>IEEE Transactions on Image Processing (TIP), 2021
  <a href="https://ieeexplore.ieee.org/abstract/document/9376632">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>GR-PSN: Learning to Estimate Surface Normal and Reconstruct Photometric Stereo Images <br />
  <b>Yakun Ju</b>, Boxin Shi, Yang Chen, Huiyu Zhou, Junyu Dong, Kin-Man Lam <br />
<i>IEEE Transactions on Visualization and Computer Graphics (TVCG), 2023
  <a href="https://ieeexplore.ieee.org/abstract/document/10306333">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>Estimating Highresolution Surface Normals via Low-resolution Photometric Stereo Images <br />
  <b>Yakun Ju</b>, Muwei Jian, Cong Wang, Cong Zhang, Junyu Dong, Kin-Man Lam<br />
<i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023 (ESI Highly Cited Paper)
  <a href="https://ieeexplore.ieee.org/abstract/document/10208243">[Paper]</a>
</i></p>
</li>
</ul>


<ul> <li><p>Underwater Surface Normal Reconstruction via Cross-grained Photometric Stereo Transformer <br />
  <b>Yakun Ju</b>, Ling Li, Xian Zhong, Yuan Rao, Yanru Liu, Junyu Dong, Alex C. Kot<br />
<i>IEEE Journal of Oceanic Engineering (JOE), 2024
  <a href="https://ieeexplore-ieee-org.remotexs.ntu.edu.sg/document/10721286">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>Towards Marine Snow Removal with Fusing Fourier Information <br />
  <b>Yakun Ju</b>, Jun Xiao, Cong Zhang, Hao Xie, Anwei Luo, Huiyu Zhou, Alex C. Kot<br />
<i>Information Fusion (INFFUS), 2024
  <a href="https://link.springer.com/article/10.1007/s41095-021-0223-y">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>Learning Conditional Photometric Stereo with High-resolution Features <br />
  <b>Yakun Ju</b>, Yuxin Peng, Muwei Jian, Feng Gao, Junyu Dong<br />
<i>Computational Visual Media (CVMJ), 2022
  <a href="https://link.springer.com/article/10.1007/s41095-021-0223-y">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>A dual-cue network for multispectral photometric stereo <br />
  <b>Yakun Ju</b>, Xinghui Dong, Yingyu Wang, Lin Qi, Junyu Dong<br />
<i>Pattern Recognition (PR), 2020 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320319304625">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>Learning Conditional Photometric Stereo with High-resolution Features <br />
  <b>Yakun Ju</b>, Kin-Man Lam, Yang Chen, Lin Qi, Junyu Dong<br />
<i>International Conference on International Joint Conferences on Artificial Intelligence (IJCAI), 2020 
  <a href="https://www.researchgate.net/profile/Yakun-Ju/publication/342793045_Pay_Attention_to_Devils_A_Photometric_Stereo_Network_for_Better_Details/links/5f0a91bca6fdcc4ca4635804/Pay-Attention-to-Devils-A-Photometric-Stereo-Network-for-Better-Details.pdf">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>FNIN: A Fourier Neural Operator-based Numerical Integration Network for Surface-from-gradients<br />
Jiaqi Leng, <b>Yakun Ju*</b>, Yuanxu Duan, JiangnanZhang, Qingxuan Lv, Zuxuan Wu, Hao Fan<br />
<i>Annual AAAI Conference on Artificial Intelligence (AAAI), 2025 
  <a href="https://aaai.org/conference/aaai/aaai-25/">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>A deep-shallow and global–local multi-feature fusion network for photometric stereo<br />
Yanru Liu, <b>Yakun Ju*</b>, Muwei Jian, Feng Gao, Yuan Rao, Yeqi Hu, Junyu Dong<br />
<i>Image and Vision Computing (IVC), 2022 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885621002730">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>A Structure-Affinity Dual Attention-based Network to Segment Spine for Scoliosis Assessment <br />
Hao Xie, Zixun Huang, Frank H.F. Leung, <b>Yakun Ju*</b>, Yong-Ping Zheng, Sai Ho Ling<br />
<i>IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2023
  <a href="https://ieeexplore.ieee.org/abstract/document/10385419">[Paper]</a>
</i></p>
</li>
</ul>		

<ul> <li><p>Learning General Descriptors for Image Matching with Regression Feedback <br />
Yuan Rao, <b>Yakun Ju</b>, Cong Li, Eric Rigall, Jian Yang, Hao Fan, Junyu Dong<br />
<i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023
  <a href="https://ieeexplore.ieee.org/abstract/document/10102528">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>3D Hand Pose Estimation from Monocular RGB with Feature Interaction Module <br />
Shaoxiang Guo, Eric Rigall, <b>Yakun Ju</b>, Junyu Dong<br />
<i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2022
  <a href="https://ieeexplore.ieee.org/abstract/document/9680673">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>Efficient Inductive Vision Transformer for Oriented Object Detection in Remote Sensing Imagery <br />
Cong Zhang, Jingran Su, <b>Yakun Ju</b>, Kin-Man Lam, Qi Wang<br />
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2023 (ESI Highly Cited Paper)
  <a href="https://ieeexplore.ieee.org/abstract/document/10173572">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>	
Dynamic Mutual Learning for Object Detection in Aerial Imagery <br />
Cong Zhang, Chuang Yang, <b>Yakun Ju</b>, Jun Xiao, Muwei Jian, Kin-Man Lam, Qi Wang<br />
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2026 
  <a href="https://ieeexplore.ieee.org/abstract/document/11367040">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>DA-GAN: Dual-Attention GAN for Underwater Image Enhancement With Contrast and Color Correction <br />
Xiaopng Liu, Honghao Xu, <b>Yakun Ju</b>, Shengke Wang, Cong Liu, Long Chen<br />
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2026
  <a href="https://ieeexplore.ieee.org/document/11322545">[Paper]</a>
</i></p>
</li>
</ul>	


<ul> <li><p>pmBQA: Projection-based Blind Point Cloud Quality Assessment via Multimodal Learning <br />
Wuyuan Xie, Kaimin Wang, <b>Yakun Ju</b>, Miaohui Wang<br />
<i>ACM International Conference on Multimedia (MM), 2023
  <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611998">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>DCD-UIE: Decoupled Chromatic Diffusion Model for Underwater Image Enhancement <br />
Guodong Fan, Yu Zhou, Jingchun Zhou, <b>Yakun Ju</b>, Guang-Yong Chen, Jinjiang Li, Alex C. Kot<br />
<i>IEEE Transactions on Image Processing (TIP), 2026
  <a href="https://ieeexplore.ieee.org/document/11339364">[Paper]</a>
</i></p>
</li>
</ul>

	
<ul> <li><p>Flow-Edge-Net: Video Saliency Detection Based on Optical Flow and Edge-Weighted Balance Loss <br />
Muwei Jian, Xiangwei Lu, Xiaoyang Yu, <b>Yakun Ju</b>, Hui Yu, Kin-Man Lam<br />
<i>IEEE Transactions on Computational Social Systems (TCSS), 2023
  <a href="https://ieeexplore.ieee.org/abstract/document/101345304">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>Prototype-driven structure synergy network for remote sensing images segmentation <br />
Junyi Wang, Jinjiang Li, Guodong Fan, <b>Yakun Ju</b>, Xiang Fang, Alex C. Kot<br />
<i>EEE Transactions on Geoscience and Remote Sensing (TRGS), 2025
  <a href="https://ieeexplore.ieee.org/abstract/document/11206537">[Paper]</a>
</i></p>
</li>
</ul>	
	
<ul> <li><p>Towards Progressive Multi-Frequency Representation for Image Warping <br />
Jun Xiao, Zihang Lyu, Cong Zhang, <b>Yakun Ju</b>,  Changjian Shui, Kin-Man Lam<br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024
  <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Towards_Progressive_Multi-Frequency_Representation_for_Image_Warping_CVPR_2024_paper.html">[Paper]</a>
</i></p>
</li>
</ul>	

<ul> <li><p>Cross-Frequency Attention and Color Contrast Constraint for Remote Sensing Dehazing <br />
Yuxin Feng, Jufeng Li, Tao Huang, Fangfang Wu, <b>Yakun Ju</b>, Chunxu Li, Weisheng Dong, Alex C. Kot<br />
<i>IEEE Transactions on Image Processing (TIP), 2026
  <a href="https://ieeexplore.ieee.org/document/11339364">[Paper]</a>
</i></p>
</li>
</ul>

<ul> <li><p>Exposing Image Splicing Traces in Scientific Publications via Uncertainty-guided Refinement <br />
 Xun Lin, Wenzhong Tang, Haoran Wang, Yizhong Liu, <b>Yakun Ju</b>, Shuai Wang, Zitong Yu <br />
<i>Patterns - Cell Press, 2024
  <a href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00180-6#%20">[Paper]</a>
</i></p>
</li>
</ul>
	
<ul> <li><p>Promptrestorer: A prompting image restoration method with degradation perception <br />
Cong Wang, Jinshan Pan, Wei Wang, Jiangxin Dong, Mengzhu Wang, <b>Yakun Ju</b>, Junyang Chen<br />
<i>Advances in Neural Information Processing Systems (NeurIPS), 2023
  <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/1c364d98a5cdc426fd8c76fbb2c10e34-Abstract-Conference.html">[Paper]</a>
</i></p>
</li>
</ul>	

<h2>Awards</h2>
<ul>
<li><p> ACM China Council Qingdao Chapter Outstanding Doctoral Dissertation Award, 2022 <br /> 
<li><p> National Scholarship for Doctoral Students, 2020  <br /> 
<li><p> Outstanding Graduates of Shandong Province, 2022 <br /> 
<li><p> Inspur Scholarship, 2021 <br /> 
<li><p> Goers Acoustic Scholarship, 2017 <br />
</ul>
  

<h2>Granted Patents</h2>
<ul>  
<li><p> A Single Frame Image 3D Reconstruction Device and Method Based on Deep Learning, CN107862741A, <b>Yakun Ju</b>, Junyu Dong, Lin Qi, Liang Lu
<li><p> High-frequency Region Enhancement Photometric Stereo Method Based on Deep Learning, CN110060212A, <b>Yakun Ju</b>, Junyu Dong, Feng Gao
<li><p> Multispectral photometric stereo surface normal recovery method based on deep learning, CN113936117A, <b>Yakun Ju</b>, Junyu Dong, Lin Qi
<li><p> A Transformer-based face image super-resolution method, CN113191953A, Muwei Jian, Rui Wang, Xing Wang, <b>Yakun Ju</b>, etc.
<li><p> A method for grading diabetic retinopathy based on a three-stage attention network, CN115587979A, Muwei Jian, Hongyu Chen, Rui Wang, <b>Yakun Ju</b>, etc.
<li><p> Low-resolution face super-resolution and recognition method based on facial prior knowledge, CN113128467A, Muwei Jian, Rui Wang, Xing Wang, Ji Chen, <b>Yakun Ju</b>, etc.
<li><p> Mixed facial component recognition method based on non-uniform illumination face image enhancement, CN113239823A, Muwei Jian, Rui Wang, Xing Wang, Chengdong Li, <b>Yakun Ju</b>, etc.
</ul>



<h2>Map My Visitors</h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=200&t=n&d=DUZ5ltq0MZsKYFClVz-_l6DGjjcuIilnJvRuR-Ubh9w&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>
</ul>

  
  
  

  
  
